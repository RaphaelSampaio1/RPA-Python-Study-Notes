> #Robots.txt

Ex.: https://www.instagram.com/robots.txt |  http://github.com/robots.txt

This path show up the botnames allowed to use and prohibited pages to scrap.


* User-agent : Bot name
* Disallow : List of pages that the site doesn't want that be extracted


Usually, structed sites contains this path
